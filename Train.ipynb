{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils\n",
    "Utils.set_seed(Utils.seed)\n",
    "\n",
    "import Dataloader,  Model\n",
    "import torch\n",
    "import tqdm\n",
    "import numpy                as  np\n",
    "import matplotlib.pyplot    as  plt\n",
    "import torch.nn             as  nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Wavelet transform (CWT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales = np.arange(1, Utils.Scales)\n",
    "\n",
    "# for wavelet in reversed(Utils.wavelet_lis):\n",
    "#     # Perform Continuous Wavelet Transform\n",
    "#     print(wavelet)\n",
    "#     coefficients, frequencies = pywt.cwt(Dataloader.X_numpy[1,:Utils.input_horizon], scales, wavelet)\n",
    "\n",
    "#     # # Plot the results\n",
    "#     # plt.figure(figsize=(10, 6))\n",
    "#     # plt.imshow(np.abs(coefficients), extent=[0, 1, 1, Scales], aspect='auto', cmap='jet')\n",
    "#     # # plt.colorbar(label='Magnitude')\n",
    "#     # plt.title('Continuous Wavelet Transform')\n",
    "#     # plt.xlabel('Time')\n",
    "#     # plt.ylabel('Scale')\n",
    "#     # plt.show()\n",
    "\n",
    "# if Utils.Coefficient_Real:\n",
    "#     coefficients = np.abs(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input_size   = Utils.input_horizon\n",
    "epochs                  = Utils.num_epochs\n",
    "\n",
    "model     = Model.Structure().to(device = Utils.Device)\n",
    "criterion = torch.nn.BCELoss()#torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "                            model.parameters(),\n",
    "                            lr=1e-6,\n",
    "                            # momentum=0.9,\n",
    "                            # weight_decay=1e-4\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1- Test : 0: 100%|██████████| 162/162 [00:02<00:00, 55.07it/s, loss_batch=0.7420144]\n",
      "epoch=1- Test : 1: 100%|██████████| 162/162 [00:02<00:00, 76.94it/s, loss_batch=0.7438366]\n",
      "epoch=1- Test : 2: 100%|██████████| 162/162 [00:02<00:00, 67.52it/s, loss_batch=0.7621051]\n",
      "epoch=1- Test : 3: 100%|██████████| 162/162 [00:02<00:00, 73.24it/s, loss_batch=0.7433118]\n",
      "epoch=1- Test : 4: 100%|██████████| 162/162 [00:02<00:00, 70.33it/s, loss_batch=0.7604607]\n",
      "epoch=1- Test : 5: 100%|██████████| 162/162 [00:02<00:00, 72.88it/s, loss_batch=0.7481516]\n",
      "epoch=1- Test : 6: 100%|██████████| 162/162 [00:02<00:00, 68.44it/s, loss_batch=0.7460793]\n",
      "epoch=1- Test : 7: 100%|██████████| 162/162 [00:02<00:00, 71.89it/s, loss_batch=0.7492654]\n",
      "epoch=1- Test : 8: 100%|██████████| 162/162 [00:02<00:00, 71.27it/s, loss_batch=0.7430425]\n",
      "epoch=1- Test : 9: 100%|██████████| 162/162 [00:02<00:00, 73.43it/s, loss_batch=0.6961030]\n",
      "epoch=1- Test : 10: 100%|██████████| 162/162 [00:02<00:00, 72.09it/s, loss_batch=0.7439010]\n",
      "epoch=1- Test : 11: 100%|██████████| 162/162 [00:02<00:00, 72.96it/s, loss_batch=0.7343745]\n",
      "epoch=1- Test : 12: 100%|██████████| 162/162 [00:02<00:00, 71.56it/s, loss_batch=0.7438860]\n",
      "epoch=1- Test : 13: 100%|██████████| 162/162 [00:02<00:00, 68.54it/s, loss_batch=0.7300885]\n",
      "epoch=1- Test : 14: 100%|██████████| 162/162 [00:02<00:00, 72.47it/s, loss_batch=0.7106503]\n",
      "epoch=1- Test : 15: 100%|██████████| 162/162 [00:02<00:00, 67.22it/s, loss_batch=0.7278953]\n",
      "epoch=1- Test : 16: 100%|██████████| 162/162 [00:02<00:00, 70.48it/s, loss_batch=0.7327884]\n",
      "epoch=1- Test : 17: 100%|██████████| 162/162 [00:02<00:00, 70.87it/s, loss_batch=0.7306759]\n",
      "epoch=1- Test : 18: 100%|██████████| 162/162 [00:02<00:00, 68.91it/s, loss_batch=0.7459482]\n",
      "epoch=1- Test : 19: 100%|██████████| 162/162 [00:02<00:00, 70.40it/s, loss_batch=0.7249795]\n",
      "epoch=1- Test : 20: 100%|██████████| 162/162 [00:02<00:00, 67.45it/s, loss_batch=0.7328243]\n",
      "epoch=1- Test : 21: 100%|██████████| 162/162 [00:02<00:00, 65.17it/s, loss_batch=0.7454032]\n",
      "epoch=1- Test : 22: 100%|██████████| 162/162 [00:02<00:00, 80.66it/s, loss_batch=0.7372389]\n",
      "epoch=1- Test : 23: 100%|██████████| 162/162 [00:01<00:00, 83.67it/s, loss_batch=0.7138314]\n",
      "epoch=1- Test : 24: 100%|██████████| 162/162 [00:01<00:00, 81.35it/s, loss_batch=0.7183790]\n",
      "epoch=1- Test : 25: 100%|██████████| 162/162 [00:01<00:00, 84.23it/s, loss_batch=0.7121577]\n",
      "epoch=1- Test : 26: 100%|██████████| 162/162 [00:01<00:00, 81.55it/s, loss_batch=0.7244833]\n",
      "epoch=1- Test : 27: 100%|██████████| 162/162 [00:01<00:00, 86.28it/s, loss_batch=0.7081321]\n",
      "epoch=1- Test : 28: 100%|██████████| 162/162 [00:02<00:00, 80.21it/s, loss_batch=0.7063621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2- Test : 0: 100%|██████████| 162/162 [00:01<00:00, 82.64it/s, loss_batch=0.7116814]\n",
      "epoch=2- Test : 1: 100%|██████████| 162/162 [00:01<00:00, 81.90it/s, loss_batch=0.7022913]\n",
      "epoch=2- Test : 2: 100%|██████████| 162/162 [00:01<00:00, 86.27it/s, loss_batch=0.7005318]\n",
      "epoch=2- Test : 3: 100%|██████████| 162/162 [00:01<00:00, 83.94it/s, loss_batch=0.7011720]\n",
      "epoch=2- Test : 4: 100%|██████████| 162/162 [00:01<00:00, 83.24it/s, loss_batch=0.7031617]\n",
      "epoch=2- Test : 5: 100%|██████████| 162/162 [00:01<00:00, 82.47it/s, loss_batch=0.7013988]\n",
      "epoch=2- Test : 6: 100%|██████████| 162/162 [00:01<00:00, 83.85it/s, loss_batch=0.6984578]\n",
      "epoch=2- Test : 7: 100%|██████████| 162/162 [00:01<00:00, 82.56it/s, loss_batch=0.6980458]\n",
      "epoch=2- Test : 8: 100%|██████████| 162/162 [00:01<00:00, 81.67it/s, loss_batch=0.6946314]\n",
      "epoch=2- Test : 9:  24%|██▍       | 39/162 [00:00<00:01, 72.28it/s, loss_batch=0.7019883]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2- Test : 9: 100%|██████████| 162/162 [00:02<00:00, 62.72it/s, loss_batch=0.6955478]\n",
      "epoch=2- Test : 10:   8%|▊         | 13/162 [00:00<00:02, 58.42it/s, loss_batch=0.6906242]"
     ]
    }
   ],
   "source": [
    "loss_t = []\n",
    "\n",
    "ll = (Dataloader.X_numpy.shape[1]//prediction_input_size)-1\n",
    "for epoch in range(1,epochs+3):\n",
    "    print(ll)\n",
    "\n",
    "    for test in range(Dataloader.X_numpy.shape[0]):\n",
    "        loop_train = tqdm.tqdm(range(ll),total=ll,desc=\"train\",position=0,leave=True)\n",
    "        loss_train_list = []\n",
    "        if test==10 or test==2:\n",
    "            continiu\n",
    "\n",
    "        for Batch in loop_train:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x = Dataloader.X_numpy[test,Batch*prediction_input_size:(Batch+1)*prediction_input_size]\n",
    "            y = Dataloader.X_numpy[test,Batch*prediction_input_size: Batch*prediction_input_size+1]\n",
    "\n",
    "            prediction = model.forward(x)\n",
    "\n",
    "\n",
    "            loss_train = criterion(prediction, torch.tensor(y.reshape(1,1),dtype=torch.float32).to(device=Utils.Device))\n",
    "            # Back propagation\n",
    "            loss_train.backward()\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "            loss_train_list.append(loss_train)\n",
    "            \n",
    "            if Batch%10 == 0:\n",
    "                # print(loss_train)\n",
    "                loop_train.set_description(f\"{epoch=}- Test : {test}\")\n",
    "                loop_train.set_postfix(\n",
    "                    loss_batch=\"{:.7f}\".format(torch.tensor(loss_train_list).mean()),refresh=True,)\n",
    "                \n",
    "        loss_t.append(torch.tensor(loss_train_list).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
