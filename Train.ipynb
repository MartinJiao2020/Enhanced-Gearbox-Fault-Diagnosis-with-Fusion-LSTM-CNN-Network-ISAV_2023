{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pywt\n",
    "import pandas               as  pd\n",
    "import numpy                as  np\n",
    "import matplotlib.pyplot    as  plt\n",
    "import torch.nn             as  nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "samples_per_test    = 32768\n",
    "Total_test          = 29\n",
    "test_Duration       = 2\n",
    "\n",
    "# model         Maybe adding dropout in LSTM is good\n",
    "input_horizon       = 200\n",
    "# model-LSTM\n",
    "LSTM_outFeature     = 100\n",
    "LSTM_NumLayer       = 2\n",
    "LSTM_hidden_size    = 64\n",
    "\n",
    "# CWT\n",
    "Scales              = 50\n",
    "wavelet_lis         = ['mexh','morl','gaus1','cmor1-1.0']   # Define the wavelet and scales\n",
    "wavelet             = wavelet_lis[1]                        # You can choose other wavelet functions as well\n",
    "Coefficient_Real    = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading dataset\n",
    "Read the CSV file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_BinaryClass.csv')\n",
    "df['Faulty'] = df['Faulty'].replace({False: 0, True: 1})\n",
    "\n",
    "\"\"\"\n",
    "print(df.head())\n",
    "\n",
    "its better to keep numpy format because CWT uses numpy and before network make it pytorch\n",
    "\n",
    "X = torch.tensor(df['Datas' ].values).reshape(Total_test,samples_per_test)\n",
    "Y = torch.tensor(df['Faulty'].values).reshape(Total_test,samples_per_test)\n",
    "\"\"\"\n",
    "\n",
    "X_numpy = df['Datas' ].values.reshape(Total_test,samples_per_test)\n",
    "Y_numpy = df['Faulty'].values.reshape(Total_test,samples_per_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Wavelet transform (CWT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = np.arange(1, Scales)\n",
    "\n",
    "for wavelet in reversed(wavelet_lis):\n",
    "    # Perform Continuous Wavelet Transform\n",
    "    print(wavelet)\n",
    "    coefficients, frequencies = pywt.cwt(X_numpy[1,:input_horizon], scales, wavelet)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(np.abs(coefficients), extent=[0, 1, 1, Scales], aspect='auto', cmap='jet')\n",
    "    plt.colorbar(label='Magnitude')\n",
    "    plt.title('Continuous Wavelet Transform')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Scale')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Coefficient_Real:\n",
    "    coefficients = np.abs(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size  :int ,\n",
    "                hidden_size :int    = LSTM_hidden_size,\n",
    "                num_layers  :int    = LSTM_NumLayer,\n",
    "                output_size :int    = LSTM_outFeature,\n",
    "                DropOut     :float  = 0)->None:\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.num_layers     = num_layers\n",
    "        \n",
    "        self.lstm           = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc             = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x)->tuple:\n",
    "        out, (h_state,C_state) = self.lstm(x)\n",
    "        \n",
    "        # Decode the hidden state of the last time step using the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out,h_state,C_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in ``` h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device) ``` x is input and data will be generated in device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input data shape\n",
    "sequence_length = 49\n",
    "input_size = 200\n",
    "output_size = 1  # For example, predicting a single value\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "\n",
    "# Create the LSTM model\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Generate random input data\n",
    "input_data = torch.randn(1, sequence_length, input_size)  # Batch size of 1 for this example\n",
    "\n",
    "# Forward pass\n",
    "output,h_state,C_state = model(input_data)\n",
    "\n",
    "print(\"Output shape:\", output.shape,h_state.shape,C_state.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
