{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Utils\n",
    "Utils.set_seed(Utils.seed)\n",
    "\n",
    "import Dataloader,  Model\n",
    "import torch\n",
    "import pywt\n",
    "import pandas               as  pd\n",
    "import numpy                as  np\n",
    "import matplotlib.pyplot    as  plt\n",
    "import torch.nn             as  nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Wavelet transform (CWT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmor1-1.0\n",
      "gaus1\n",
      "morl\n",
      "mexh\n"
     ]
    }
   ],
   "source": [
    "scales = np.arange(1, Scales)\n",
    "\n",
    "for wavelet in reversed(wavelet_lis):\n",
    "    # Perform Continuous Wavelet Transform\n",
    "    print(wavelet)\n",
    "    coefficients, frequencies = pywt.cwt(X_numpy[1,:input_horizon], scales, wavelet)\n",
    "\n",
    "    # # Plot the results\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.imshow(np.abs(coefficients), extent=[0, 1, 1, Scales], aspect='auto', cmap='jet')\n",
    "    # # plt.colorbar(label='Magnitude')\n",
    "    # plt.title('Continuous Wavelet Transform')\n",
    "    # plt.xlabel('Time')\n",
    "    # plt.ylabel('Scale')\n",
    "    # plt.show()\n",
    "\n",
    "if Coefficient_Real:\n",
    "    coefficients = np.abs(coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_horizon   :int ,\n",
    "                hidden_size     :int    = LSTM_hidden_size,\n",
    "                num_layers      :int    = LSTM_NumLayer,\n",
    "                output_size     :int    = LSTM_outFeature,\n",
    "                DropOut         :float  = 0)->None:\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size    = hidden_size\n",
    "        self.num_layers     = num_layers\n",
    "        \n",
    "        self.lstm           = nn.LSTM(input_horizon, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc             = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x)->tuple:\n",
    "        out, (h_state,C_state) = self.lstm(x)\n",
    "        \n",
    "        print(out.shape)\n",
    "        if len(out.shape)==2:\n",
    "            out = self.fc(out[:, :])\n",
    "        if len(out.shape)==3:\n",
    "            out = self.fc(out[:, -1, :])\n",
    "        return out#,h_state,C_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in ``` h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device) ``` x is input and data will be generated in device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "Output shape: torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMModel(input_horizon)\n",
    "output = model(torch.tensor(X_numpy[1,:input_horizon], dtype=torch.float32).unsqueeze(0)) # coefficients\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channel):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channel = out_channel\n",
    "        # 1x1 convolution branch\n",
    "        \n",
    "        self.conv1x1        =   nn.Conv2d(self.in_channels, self.out_channel, kernel_size=1)\n",
    "        \n",
    "    \n",
    "        # 1x1 conv followed by 2x2 conv branch\n",
    "        self.conv2x2_reduce =   nn.Conv2d(self.in_channels, self.out_channel, kernel_size=1)\n",
    "        self.conv2x2        =   nn.Conv2d(self.out_channel, self.out_channel, kernel_size=2, padding='same')\n",
    "\n",
    "\n",
    "        # 1x1 conv followed by 5x5 conv branch\n",
    "        self.conv5x5_reduce =   nn.Conv2d(self.in_channels, self.out_channel, kernel_size=1)\n",
    "        self.conv5x5        =   nn.Conv2d(self.out_channel, self.out_channel, kernel_size=5, padding='same')\n",
    "        \n",
    "        # 1x1 conv followed by 8x8 conv branch\n",
    "        self.conv8x8_reduce =   nn.Conv2d(self.in_channels, self.out_channel, kernel_size=1)\n",
    "        self.conv8x8        =   nn.Conv2d(self.out_channel, self.out_channel, kernel_size=8, padding='same')\n",
    "\n",
    "        # 3x3 pooling followed by 1x1 conv branch\n",
    "        self.pool           =   nn.MaxPool2d(kernel_size=3, stride=1, padding = 1)\n",
    "        self.conv1x1_pool   =   nn.Conv2d(self.in_channels,  self.out_channel, kernel_size=1)\n",
    "\n",
    "        self.head           =   model = nn.Sequential(\n",
    "                                                        nn.Conv2d(50,100, kernel_size=(4,16),stride=2, padding=0),\n",
    "                                                        nn.ReLU(),\n",
    "                                                        nn.Conv2d(100,100, kernel_size=(4,16),stride=3, padding=0),\n",
    "                                                        nn.ReLU(),\n",
    "                                                    )\n",
    "    def GAP(self, x):\n",
    "        return torch.mean(x, dim=[2, 3])    \n",
    "         \n",
    "    def forward(self, x):\n",
    "        out1x1 = self.conv1x1(x)\n",
    "        \n",
    "        out2x2 = self.conv2x2_reduce(x)\n",
    "        out2x2 = self.conv2x2(out2x2)\n",
    "        \n",
    "        out5x5 = self.conv5x5_reduce(x)\n",
    "        out5x5 = self.conv5x5(out5x5)\n",
    "\n",
    "        out8x8 = self.conv8x8_reduce(x)\n",
    "        out8x8 = self.conv8x8(out8x8)\n",
    "        \n",
    "        out1x1_pool = self.pool(x)\n",
    "        out1x1_pool = self.conv1x1_pool(out1x1_pool)\n",
    "        \n",
    "        out = torch.cat([out1x1, out2x2, out5x5,out8x8, out1x1_pool], dim=1)\n",
    "\n",
    "        out = self.GAP(self.head(out))\n",
    "        return out\n",
    "\n",
    "# Example usage\n",
    "ddd = torch.tensor(coefficients, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "inception_block = InceptionBlock(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.3556e-03, 6.6829e-02, 7.5652e-04, 4.1845e-04, 8.6883e-02, 2.7851e-04,\n",
       "         9.8218e-02, 1.0008e-01, 8.5369e-03, 3.5907e-02, 7.2679e-04, 3.9750e-02,\n",
       "         0.0000e+00, 1.1543e-01, 2.2967e-02, 0.0000e+00, 8.7291e-02, 1.8153e-01,\n",
       "         5.2311e-02, 0.0000e+00, 1.0640e-02, 0.0000e+00, 2.9450e-02, 7.5638e-04,\n",
       "         1.9598e-02, 1.5769e-03, 4.0454e-02, 5.9619e-02, 5.6235e-03, 8.1631e-02,\n",
       "         2.6434e-02, 0.0000e+00, 1.4095e-03, 8.9980e-05, 0.0000e+00, 1.1944e-01,\n",
       "         0.0000e+00, 0.0000e+00, 6.8937e-02, 6.6008e-02, 0.0000e+00, 6.8599e-02,\n",
       "         1.6879e-04, 9.4618e-03, 2.9779e-01, 5.8568e-05, 2.1640e-02, 3.9576e-02,\n",
       "         0.0000e+00, 1.6244e-01, 1.0700e-02, 1.5783e-03, 5.3735e-03, 4.4955e-03,\n",
       "         1.0302e-02, 4.9943e-03, 2.0423e-03, 1.7578e-01, 9.0084e-02, 3.6780e-04,\n",
       "         2.7682e-02, 2.5864e-02, 1.4793e-01, 8.2999e-04, 2.5155e-02, 0.0000e+00,\n",
       "         1.0490e-01, 0.0000e+00, 6.7329e-02, 1.6723e-01, 0.0000e+00, 5.8986e-02,\n",
       "         2.3026e-02, 2.0044e-01, 0.0000e+00, 1.8263e-01, 0.0000e+00, 1.4574e-01,\n",
       "         7.8887e-02, 1.3000e-01, 0.0000e+00, 1.2849e-01, 1.4649e-01, 2.1114e-02,\n",
       "         0.0000e+00, 0.0000e+00, 1.0685e-02, 5.5940e-02, 6.6280e-02, 1.5639e-03,\n",
       "         0.0000e+00, 4.9263e-02, 8.6225e-02, 3.2175e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.9234e-02, 1.5630e-01, 9.8947e-02, 1.0379e-01]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_t = inception_block(ddd)\n",
    "_t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
