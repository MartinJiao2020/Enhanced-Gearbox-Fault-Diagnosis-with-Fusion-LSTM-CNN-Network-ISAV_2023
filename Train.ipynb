{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  Utils\n",
    "Utils.set_seed(Utils.seed)\n",
    "\n",
    "import  Dataloader,  Model\n",
    "import  torch\n",
    "import  tqdm\n",
    "import  numpy                   as  np\n",
    "import  matplotlib.pyplot       as  plt\n",
    "import  torch.nn                as  nn\n",
    "\n",
    "from    sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input_size   = Utils.input_horizon\n",
    "epochs                  = Utils.num_epochs\n",
    "# Simp_Conv().to(device = Utils.Device)#ResNetFeatureExtractor().to(device = Utils.Device)#\n",
    "model     = Model.Structure_CNN_RNN().to(device = Utils.Device)\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing = 0.3)\n",
    "optimizer = torch.optim.Adam(\n",
    "                            model.parameters(),\n",
    "                            lr=1e-4,\n",
    "                            # momentum=0.9,\n",
    "                            weight_decay=1e-3\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1- Test : 16 y=array([0, 1]): 100%|██████████| 440/440 [03:28<00:00,  2.11it/s, Accu=94.93654, loss_batch=0.4862832]\n"
     ]
    }
   ],
   "source": [
    "loss_t = []\n",
    "ll = (Dataloader.X_numpy.shape[1]//prediction_input_size)-1\n",
    "for epoch in range(1,epochs+1):\n",
    "    # print(ll)\n",
    "    loop_train = tqdm.tqdm(range(ll),total=ll,desc=\"train\",position=0,leave=True)\n",
    "    loss_train_list = []\n",
    "\n",
    "    j = 0\n",
    "    accu = 0\n",
    "    for Batch in loop_train:#range(Dataloader.X_numpy.shape[0]):\n",
    "        for test in range(17):#[np.where(Dataloader.Test_ID_numpy[:,0] == data)[0][0] for data in [1,4,5,6,7,9,11,12,19,24,26,27]]:#28,29\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x = Dataloader.X_numpy[test,Batch*prediction_input_size:(Batch+1)*prediction_input_size]+np.random.random(size=(prediction_input_size))/7\n",
    "            y = Dataloader.Y_numpy[test,Batch*prediction_input_size: Batch*prediction_input_size+1]\n",
    "            x = (x-x.mean())/x.std()\n",
    "            prediction = model.forward(x)\n",
    "\n",
    "            if torch.argmax(prediction).item() == y:\n",
    "                accu +=1\n",
    "            j += 1    \n",
    "            \n",
    "            if y==0:\n",
    "                y = np.array([1,0])\n",
    "            else:\n",
    "                y = np.array([0,1])\n",
    "\n",
    "            loss_train = criterion(prediction, torch.tensor(y.reshape(1,2),dtype=torch.float32).to(device=Utils.Device))\n",
    "            # Back propagation\n",
    "            loss_train.backward()\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "            loss_train_list.append(loss_train)\n",
    "            \n",
    "            if Batch%10 == 0:\n",
    "                # print(loss_train)\n",
    "                loop_train.set_description(f\"{epoch=}- Test : {test} {y=}\")\n",
    "                loop_train.set_postfix(\n",
    "                    loss_batch=\"{:.7f}\".format(torch.tensor(loss_train_list).mean()),\n",
    "                    Accu =\"{:.5f}\".format(100*accu/j),\n",
    "                    refresh=True)\n",
    "                    \n",
    "        loss_t.append(torch.tensor(loss_train_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test : 16 y=array([1.]): 100%|██████████| 440/440 [00:11<00:00, 38.54it/s, Accu=99.30394, loss_batch=0.4855665] \n",
      "Test : 17 y=array([0.]): 100%|██████████| 440/440 [00:10<00:00, 40.53it/s, Accu=100.00000, loss_batch=0.4855665]\n",
      "Test : 18 y=array([1.]): 100%|██████████| 440/440 [00:10<00:00, 41.13it/s, Accu=99.30394, loss_batch=0.4855665]\n",
      "Test : 19 y=array([0.]): 100%|██████████| 440/440 [00:12<00:00, 35.00it/s, Accu=100.00000, loss_batch=0.4855665]\n"
     ]
    }
   ],
   "source": [
    "accu_li =[]\n",
    "\n",
    "y_list = []\n",
    "p_list = []\n",
    "\n",
    "ll = (Dataloader.X_numpy.shape[1]//prediction_input_size)-1\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for test in range(16,20):#[np.where(Dataloader.Test_ID_numpy[:,0] == data)[0][0] for data in [22,21,23,20]]:\n",
    "        loop_train = tqdm.tqdm(range(ll),total=ll,desc=\"train\",position=0,leave=True)\n",
    "        j = 0\n",
    "        accu = 0\n",
    "        for Batch in loop_train:\n",
    "            model.eval()\n",
    "\n",
    "            x = Dataloader.X_numpy[test,Batch*prediction_input_size:(Batch+1)*prediction_input_size]\n",
    "            y = Dataloader.Y_numpy[test,Batch*prediction_input_size: Batch*prediction_input_size+1]\n",
    "            v = model(x)\n",
    "            \n",
    "            y_list.append(y)\n",
    "            p_list.append(torch.argmax(v).item())\n",
    "            \n",
    "            if torch.argmax(v).item() == y:\n",
    "                accu +=1\n",
    "\n",
    "            j += 1\n",
    "            if Batch%10 == 0:\n",
    "                loop_train.set_description(f\"Test : {test} {y=}\")\n",
    "                loop_train.set_postfix(\n",
    "                    loss_batch=\"{:.7f}\".format(torch.tensor(loss_train_list).mean()),\n",
    "                    Accu =\"{:.5f}\".format(100*accu/j),refresh=True, )\n",
    "            accu_li.append(100*accu/j)\n",
    "# print(100*accu/j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[880   0]\n",
      " [  7 873]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.99      1.00      1.00       880\n",
      "     Class 1       1.00      0.99      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to PyTorch tensors if they are not already\n",
    "y_true = torch.tensor(np.array(y_list))\n",
    "y_pred = torch.tensor(np.array(p_list))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# You can also print a classification report which includes precision, recall, and F1-score.\n",
    "class_names = [\"Class 0\", \"Class 1\"]  # Replace with your class names\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
